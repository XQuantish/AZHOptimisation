{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONFIG ###\n",
    "thefile = 'prepared-20181001_prefix-pNN_input_2tag_Sig_BKGs.pickle'\n",
    "### END ###\n",
    "\n",
    "do3tag = False\n",
    "doTrainNetwork = True\n",
    "\n",
    "layer_size = 1\n",
    "dropout = None\n",
    "nepochs = 50\n",
    "batch_size = 128\n",
    "modeltag = 'nn_l{0}e{1}b{2}'.format(layer_size,nepochs,batch_size)\n",
    "\n",
    "netfile = \"model_{0}.h5\".format(modeltag)\n",
    "graphfile = \"graph_{0}.png\".format(modeltag)\n",
    "file_performance = \"perf_{0}.pickle\".format(modeltag)\n",
    "file_minmax_scaler = \"minmax_scaler.pickle\"\n",
    "file_quantile_scaler = \"quantile_scaler.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9f5a991021b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0ml1_l2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import QuantileTransformer, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assistant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "#############################################################\n",
    "def setup_custom_logger(name):\n",
    "    formatter = logging.Formatter(fmt='%(asctime)s %(levelname)-8s %(message)s',\n",
    "                                  datefmt='%Y-%m-%d %H:%M:%S')\n",
    "    handler = logging.FileHandler('log.txt', mode='w')\n",
    "    handler.setFormatter(formatter)\n",
    "    screen_handler = logging.StreamHandler(stream=sys.stdout)\n",
    "    screen_handler.setFormatter(formatter)\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(handler)\n",
    "    logger.addHandler(screen_handler)\n",
    "    return logger\n",
    "\n",
    "#############################################################\n",
    "def get_model(n_invars, n_hidden_nodes, regularization=None, dropout=None):\n",
    "    if not isinstance(n_hidden_nodes, list):\n",
    "        n_hidden_nodes = [n_hidden_nodes]\n",
    "\n",
    "    x = Input(shape=(n_invars,))\n",
    "    d = x\n",
    "    for n in n_hidden_nodes:\n",
    "        d = Dense(n, activation=\"relu\", kernel_regularizer=regularization)(d)\n",
    "        if dropout:\n",
    "            d = Dropout(dropout)(d)\n",
    "    y = Dense(1, activation=\"sigmoid\")(d)\n",
    "    return Model(x, y)\n",
    "##########################################################\n",
    "def preprocess(X, quantile_trsf=None, minmax_trsf=None):\n",
    "    if quantile_trsf is None and minmax_trsf is None:\n",
    "        quantile_trsf = QuantileTransformer()\n",
    "        minmax_trsf = MinMaxScaler()\n",
    "        quantile_trsf.fit(X[:, :-1])\n",
    "        minmax_trsf.fit(X[:, -1][:, np.newaxis])\n",
    "    elif quantile_trsf is not None and minmax_trsf is not None:\n",
    "        pass\n",
    "    else:\n",
    "        return None\n",
    "    X_trsf_no_mass = quantile_trsf.transform(X[:, :-1])\n",
    "    X_trsf_mass = minmax_trsf.transform(X[:, -1][:, np.newaxis])\n",
    "\n",
    "    return quantile_trsf, minmax_trsf, np.hstack([X_trsf_no_mass, X_trsf_mass])\n",
    "##########################################################\n",
    "\n",
    "\n",
    "#############################################################\n",
    "import numpy as np\n",
    "\n",
    "# map mA,mH -> DISD\n",
    "dict_mAmH_dsid = {\n",
    "  'ggF_llbb' : {\n",
    "    (230,130) : 306939,\n",
    "    (250,130) : 306940,\n",
    "    (230,150) : 306941,\n",
    "    (300,130) : 306942,\n",
    "    (300,150) : 306943,\n",
    "    (300,200) : 306944,\n",
    "    (350,250) : 306945,\n",
    "    (400,130) : 306946,\n",
    "    (400,200) : 306948,\n",
    "    (400,250) : 344587,\n",
    "    (500,130) : 306952,\n",
    "    (500,200) : 306955,\n",
    "    (500,300) : 306958,\n",
    "    (500,350) : 308468,\n",
    "    (500,400) : 306959,\n",
    "    (600,130) : 306962,\n",
    "    (600,300) : 306966,\n",
    "    (600,400) : 344588,\n",
    "    (600,450) : 308469,\n",
    "    (600,500) : 306967,\n",
    "    (700,130) : 306968,\n",
    "    (700,200) : 306970,\n",
    "    (700,300) : 306972,\n",
    "    (700,400) : 306973,\n",
    "    (700,500) : 306974,\n",
    "    (700,600) : 308568,\n",
    "    (800,130) : 308569,\n",
    "    (800,300) : 308570,\n",
    "    (800,500) : 344589,\n",
    "    (800,700) : 308571,\n",
    "  },\n",
    "}\n",
    "\n",
    "mH_min = 130\n",
    "mH_max = 700\n",
    "mA_min = 230\n",
    "mA_max = 800\n",
    "\n",
    "# mAmH -> DSID list\n",
    "#############################################################\n",
    "# mAmH_list is a list of mA,mH pair\n",
    "# prod: ggF_llbb, bbA_llbb ...\n",
    "def mAmH2disd( mAmH_list, prod ):\n",
    "  return [ dict_mAmH_dsid[prod][(mA,mH)] for mA,mH in mAmH_list ]\n",
    "\n",
    "# random sampling of background mA and mH\n",
    "#############################################################\n",
    "# nm: mA or mH\n",
    "# the whole df\n",
    "def sample_bkg_mass(nm, df, method=0, seed=None):\n",
    "  n_bkg = (~df.IsSignal).sum()\n",
    "  m_bkg = None\n",
    "  if seed:\n",
    "    np.random.seed(seed)\n",
    "  if method==0:\n",
    "    m_bkg = np.random.choice(df[nm][~df.IsSignal],size=n_bkg)\n",
    "  else:\n",
    "    #m_bkg = np.random.uniform(np.min(m[isSig]),np.max(m[isSig]),size=n_bkg)\n",
    "    if nm == 'mA':\n",
    "      m_bkg = np.random.uniform( mA_min, mH_min, size=n_bkg)\n",
    "    if nm == 'mH':\n",
    "      m_bkg = np.random.uniform( mH_min, mA_max, size=n_bkg)\n",
    "  df.loc[~df.IsSignal, nm] = m_bkg\n",
    "\n",
    "# choose signal samples\n",
    "#############################################################\n",
    "# mAmH_list is a list of mA,mH pair\n",
    "# prod: ggF_llbb, bbA_llbb ...\n",
    "def choose_signal_samples( df, mAmH_list, prod ):\n",
    "  print('choose_signal_samples: signal tot # =',df.IsSignal.sum())\n",
    "  dsid_list = mAmH2disd( mAmH_list, prod )\n",
    "  df_chosen = df[ ((df.IsSignal) & (df.label.isin(dsid_list)) ) | (~df.IsSignal) ]\n",
    "  print('choose_signal_samples: signal tot chosen to use # =',df_chosen.IsSignal.sum() )\n",
    "  return df_chosen\n",
    "\n",
    "# list input variables\n",
    "#############################################################\n",
    "def input_variables( do3tag, df ):\n",
    "  inputs = None\n",
    "  if do3tag:\n",
    "    inputs = df[[\"lep0pt\",\"lep0eta\",\"lep0phi\",\n",
    "             \"lep1pt\",\"lep1eta\",\"lep1phi\",\n",
    "             \"jet0pt\",\"jet0eta\",\"jet0phi\",\n",
    "             \"jet1pt\",\"jet1eta\",\"jet1phi\",\n",
    "             \"jet2pt\",\"jet2eta\",\"jet2phi\",\n",
    "             \"mA\",\"mH\"]].values\n",
    "  else:\n",
    "    inputs = df[[\"lep0pt\",\"lep0eta\",\"lep0phi\",\n",
    "             \"lep1pt\",\"lep1eta\",\"lep1phi\",\n",
    "             \"jet0pt\",\"jet0eta\",\"jet0phi\",\n",
    "             \"jet1pt\",\"jet1eta\",\"jet1phi\",\n",
    "             \"mA\",\"mH\"]].values\n",
    "  return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
